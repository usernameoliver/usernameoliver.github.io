<!-- http://shoutkey.com/eager
	 http://shoutkey.com/run -->
<!DOCTYPE html>
<html lang="en">
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		
		<link rel="stylesheet" type="text/css" href="../css/myStyle.css">
		<link rel="stylesheet" type="text/css" href="../css/index.css">
		<script src="../js/jquery.js"></script>
		<script src="../js/bootstrap.js"></script>
		<script src="../index.js"></script>
		<script type="text/javascript" src="https://platform.linkedin.com/badges/js/profile.js" async defer></script>
		<style>
		* {
		  box-sizing: border-box;
		}

		body {
		  margxin: 0;
		  font-family: Arial;
		  font-size: 17px;
		}

		.container {
		  position: relative;
		  max-width: 800px;
		  margin: 0 auto;
		}

		.container img {vertical-align: middle;}

		.container .content {
		  position: absolute;
		  bottom: 0;
		  background: rgb(0, 0, 0); /* Fallback color */
		  background: rgba(0, 0, 0, 0.5); /* Black background with 0.5 opacity */
		  color: #f1f1f1;
		  width: 100%;
		  padding: 20px;
		}
		</style>
	</head>
			
	<body>

		<div class="bg">
		
		    <h1>Open-world Object Detection and Tracking</h1>


			<p>by Achal Dave</p>
            <p> This talk is a dissertation proposal at CMU</p>
			<p>There are several interesting direction of research in computer vision pointed out by Achal Dave. The first concept is generic object tracking. Previous work has been focusing on tracking object of known category. However in the real world, there is always something never met by the model. Such task is related to zero-shot learning. The method proposed by Achal is to turn a decoder to a tracker: In the training phase a neural network such as Resnet is first trained with bounding box at t = 0; In the t=k frame, the object can be tracked by the convolution of the spatial features in the t = k frame and the object feature at t = 0 frame. I really like the idea of category-agnostic tracking.</p>
            <p>Another interesting idea mentioned by Achal is to use synthetic data to train a model. The synthetic data is generated by moving the object in the original image.</p>
			<h5> <a href = 'http://usernameoliver.github.io/myWebsite/index.html'>Home</a></h5>
			<h5> <a href = 'http://usernameoliver.github.io/myWebsite/blog.html'>Blogs</a></h5>
			<h5> created on 10/18/2019</h5>
		</div>
		
		
	
	</body>
</html>
