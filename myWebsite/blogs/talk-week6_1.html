<!-- http://shoutkey.com/eager
	 http://shoutkey.com/run -->
<!DOCTYPE html>
<html lang="en">
	<head>
		<meta name="viewport" content="width=device-width, initial-scale=1">
		
		<link rel="stylesheet" type="text/css" href="../css/myStyle.css">
		<link rel="stylesheet" type="text/css" href="../css/index.css">
		<script src="../js/jquery.js"></script>
		<script src="../js/bootstrap.js"></script>
		<script src="../index.js"></script>
		<script type="text/javascript" src="https://platform.linkedin.com/badges/js/profile.js" async defer></script>
		<style>
		* {
		  box-sizing: border-box;
		}

		body {
		  margxin: 0;
		  font-family: Arial;
		  font-size: 17px;
		}

		.container {
		  position: relative;
		  max-width: 800px;
		  margin: 0 auto;
		}

		.container img {vertical-align: middle;}

		.container .content {
		  position: absolute;
		  bottom: 0;
		  background: rgb(0, 0, 0); /* Fallback color */
		  background: rgba(0, 0, 0, 0.5); /* Black background with 0.5 opacity */
		  color: #f1f1f1;
		  width: 100%;
		  padding: 20px;
		}
		</style>
	</head>
			
	<body>

		<div class="bg">
		
		    <h1>Deep Learning in Robotics</h1>


			<p>by Pieter Abbeel</p>
            <p> This talk is divided into four parts:1) Few-shot reinforcement learning; 2) Leveraging Simulation; 3) Model-based RL 4) Learning Representation for Exploration 5) Few-shot Imitation Learning </p>
			<p>I was particularly inspired by the 4th part -- Learning Representation for Exploration. Traditionally, people add noise to the input data or add noise to the model's parameters to learn a robust model. In this talk, Dr. Abbeel proposed Model Agnostic Meta-Learning. The key idea is end-to-end learning of parameter vector theta that is good init for fine-tuning for many tasks. In their approach, a small number of training data of a new task can achieve good enough performance. In details, the parameter theta_ of a new task is updated based on the parameters of the original task. The method's prerequesite is that the distribution over tasks is p(T). As a result, such method was claimed to produce good performance on few-shot learning. </p>
            <p>In medical imaging, few-shot learning is very important because we usually do not have enough training samples. This will be a future direction to research</p>

			
			<h5> <a href = 'http://usernameoliver.github.io/myWebsite/index.html'>Home</a></h5>
			<h5> <a href = 'http://usernameoliver.github.io/myWebsite/blog.html'>Blogs</a></h5>
			<h5> created on 10/01/2019</h5>
		</div>
		
		
	
	</body>
</html>
